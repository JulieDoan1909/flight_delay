{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem: Predicting Airplane Delays\n",
    "\n",
    "The goals of this notebook are:\n",
    "- Process and create a dataset from downloaded ZIP files\n",
    "- Exploratory data analysis (EDA)\n",
    "- Establish a baseline model and improve it\n",
    "\n",
    "## Introduction to business scenario\n",
    "You work for a travel booking website that is working to improve the customer experience for flights that were delayed. The company wants to create a feature to let customers know if the flight will be delayed due to weather when the customers are booking the flight to or from the busiest airports for domestic travel in the US. \n",
    "\n",
    "You are tasked with solving part of this problem by leveraging machine learning to identify whether the flight will be delayed due to weather. You have been given access to the a dataset of on-time performance of domestic flights operated by large air carriers. You can use this data to train a machine learning model to predict if the flight is going to be delayed for the busiest airports.\n",
    "\n",
    "### Dataset\n",
    "The provided dataset contains scheduled and actual departure and arrival times reported by certified US air carriers that account for at least 1 percent of domestic scheduled passenger revenues. The data was collected by the Office of Airline Information, Bureau of Transportation Statistics (BTS). The dataset contains date, time, origin, destination, airline, distance, and delay status of flights for flights between 2014 and 2018.\n",
    "The data are in 60 compressed files, where each file contains a CSV for the flight details in a month for the five years (from 2014 - 2018). The data can be downloaded from this link: [https://ucstaff-my.sharepoint.com/:f:/g/personal/ibrahim_radwan_canberra_edu_au/Er0nVreXmihEmtMz5qC5kVIB81-ugSusExPYdcyQTglfLg?e=bNO312]. Please download the data files and place them on a relative path. Dataset(s) used in this assignment were compiled by the Office of Airline Information, Bureau of Transportation Statistics (BTS), Airline On-Time Performance Data, available with the following link: [https://www.transtats.bts.gov/Fields.asp?gnoyr_VQ=FGJ]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Prepare the environment \n",
    "\n",
    "Use one of the labs which we have practised on with the Amazon Sagemakers where you perform the following steps:\n",
    "1. Start a lab.\n",
    "2. Create a notebook instance and name it \"oncloudproject\".\n",
    "3. Increase the used memory to 25 GB from the additional configurations.\n",
    "4. Open Jupyter Lab and upload this notebook into it.\n",
    "5. Upload the two combined CVS files (combined_csv_v1.csv and combined_csv_v2.csv), which you created in Part A of this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data\n",
    "\n",
    "This notebook focuses on the first dataset (`combined_csv_v2.csv`) which will be trained on a linear model and a XGBoost model. The results will be compared directly.\n",
    "\n",
    "Due to the 2h constrains of the AWS environments, this notebook is duplicated to run dataset 2 (`combined_csv_v1.csv`), `which is not convered on this notebook`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_1 = pd.read_csv(\"combined_csv_v1.csv\", index_col=0)\n",
    "df_2 = pd.read_csv(\"combined_csv_v2.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Quarter_1</th>\n",
       "      <th>Quarter_2</th>\n",
       "      <th>Quarter_3</th>\n",
       "      <th>Quarter_4</th>\n",
       "      <th>Month_1</th>\n",
       "      <th>Month_2</th>\n",
       "      <th>Month_3</th>\n",
       "      <th>Month_4</th>\n",
       "      <th>...</th>\n",
       "      <th>DepHourofDay_14</th>\n",
       "      <th>DepHourofDay_15</th>\n",
       "      <th>DepHourofDay_16</th>\n",
       "      <th>DepHourofDay_17</th>\n",
       "      <th>DepHourofDay_18</th>\n",
       "      <th>DepHourofDay_19</th>\n",
       "      <th>DepHourofDay_20</th>\n",
       "      <th>DepHourofDay_21</th>\n",
       "      <th>DepHourofDay_22</th>\n",
       "      <th>DepHourofDay_23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658125</th>\n",
       "      <td>1.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658126</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1199.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658127</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1199.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658128</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1947.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658129</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2139.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1609558 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         target  Distance  Quarter_1  Quarter_2  Quarter_3  Quarter_4  \\\n",
       "0           1.0    1587.0          1          0          0          0   \n",
       "1           0.0    1587.0          1          0          0          0   \n",
       "2           0.0     602.0          1          0          0          0   \n",
       "3           1.0     602.0          1          0          0          0   \n",
       "4           0.0     602.0          1          0          0          0   \n",
       "...         ...       ...        ...        ...        ...        ...   \n",
       "1658125     1.0     606.0          1          0          0          0   \n",
       "1658126     1.0    1199.0          1          0          0          0   \n",
       "1658127     1.0    1199.0          1          0          0          0   \n",
       "1658128     0.0    1947.0          1          0          0          0   \n",
       "1658129     0.0    2139.0          1          0          0          0   \n",
       "\n",
       "         Month_1  Month_2  Month_3  Month_4  ...  DepHourofDay_14  \\\n",
       "0              0        0        1        0  ...                0   \n",
       "1              0        0        1        0  ...                0   \n",
       "2              0        0        1        0  ...                0   \n",
       "3              0        0        1        0  ...                0   \n",
       "4              0        0        1        0  ...                0   \n",
       "...          ...      ...      ...      ...  ...              ...   \n",
       "1658125        0        1        0        0  ...                0   \n",
       "1658126        0        1        0        0  ...                0   \n",
       "1658127        0        1        0        0  ...                0   \n",
       "1658128        0        1        0        0  ...                0   \n",
       "1658129        0        1        0        0  ...                0   \n",
       "\n",
       "         DepHourofDay_15  DepHourofDay_16  DepHourofDay_17  DepHourofDay_18  \\\n",
       "0                      0                0                1                0   \n",
       "1                      0                0                0                0   \n",
       "2                      0                0                0                0   \n",
       "3                      0                0                0                0   \n",
       "4                      0                0                0                0   \n",
       "...                  ...              ...              ...              ...   \n",
       "1658125                0                0                0                0   \n",
       "1658126                0                0                0                0   \n",
       "1658127                0                0                0                0   \n",
       "1658128                0                0                0                0   \n",
       "1658129                0                0                0                0   \n",
       "\n",
       "         DepHourofDay_19  DepHourofDay_20  DepHourofDay_21  DepHourofDay_22  \\\n",
       "0                      0                0                0                0   \n",
       "1                      0                0                0                0   \n",
       "2                      0                0                0                0   \n",
       "3                      0                0                1                0   \n",
       "4                      0                1                0                0   \n",
       "...                  ...              ...              ...              ...   \n",
       "1658125                0                0                1                0   \n",
       "1658126                0                0                0                0   \n",
       "1658127                0                0                0                0   \n",
       "1658128                0                0                0                0   \n",
       "1658129                0                0                0                0   \n",
       "\n",
       "         DepHourofDay_23  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "...                  ...  \n",
       "1658125                0  \n",
       "1658126                0  \n",
       "1658127                0  \n",
       "1658128                0  \n",
       "1658129                0  \n",
       "\n",
       "[1609558 rows x 102 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.drop_duplicates(inplace=True)\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>Distance</th>\n",
       "      <th>AWND_O</th>\n",
       "      <th>PRCP_O</th>\n",
       "      <th>TAVG_O</th>\n",
       "      <th>AWND_D</th>\n",
       "      <th>PRCP_D</th>\n",
       "      <th>TAVG_D</th>\n",
       "      <th>SNOW_O</th>\n",
       "      <th>SNOW_D</th>\n",
       "      <th>...</th>\n",
       "      <th>DepHourofDay_14</th>\n",
       "      <th>DepHourofDay_15</th>\n",
       "      <th>DepHourofDay_16</th>\n",
       "      <th>DepHourofDay_17</th>\n",
       "      <th>DepHourofDay_18</th>\n",
       "      <th>DepHourofDay_19</th>\n",
       "      <th>DepHourofDay_20</th>\n",
       "      <th>DepHourofDay_21</th>\n",
       "      <th>DepHourofDay_22</th>\n",
       "      <th>DepHourofDay_23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205727</th>\n",
       "      <td>0.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205728</th>\n",
       "      <td>0.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205729</th>\n",
       "      <td>0.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205730</th>\n",
       "      <td>0.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205731</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200773 rows × 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        target  Distance  AWND_O  PRCP_O  TAVG_O  AWND_D  PRCP_D  TAVG_D  \\\n",
       "0          1.0    1587.0      20       0   206.0      38       0   134.0   \n",
       "1          0.0    1587.0      20       0   206.0      38       0   134.0   \n",
       "2          0.0     602.0      20       0   206.0      51       0    79.0   \n",
       "3          1.0     602.0      20       0   206.0      51       0    79.0   \n",
       "4          0.0     602.0      20       0   206.0      51       0    79.0   \n",
       "...        ...       ...     ...     ...     ...     ...     ...     ...   \n",
       "205727     0.0     226.0      13       0   190.0      19       0   164.0   \n",
       "205728     0.0     226.0      19       0   164.0      13       0   190.0   \n",
       "205729     0.0     226.0      13       0   190.0      19       0   164.0   \n",
       "205730     0.0     689.0      18       0   232.0      13       0   190.0   \n",
       "205731     0.0    1587.0      26       0   308.0      13       0   190.0   \n",
       "\n",
       "        SNOW_O  SNOW_D  ...  DepHourofDay_14  DepHourofDay_15  \\\n",
       "0          0.0     0.0  ...              0.0              0.0   \n",
       "1          0.0     0.0  ...              0.0              0.0   \n",
       "2          0.0     0.0  ...              0.0              0.0   \n",
       "3          0.0     0.0  ...              0.0              0.0   \n",
       "4          0.0     0.0  ...              0.0              0.0   \n",
       "...        ...     ...  ...              ...              ...   \n",
       "205727     0.0     0.0  ...              0.0              0.0   \n",
       "205728     0.0     0.0  ...              0.0              0.0   \n",
       "205729     0.0     0.0  ...              0.0              0.0   \n",
       "205730     0.0     0.0  ...              0.0              0.0   \n",
       "205731     0.0     0.0  ...              NaN              NaN   \n",
       "\n",
       "        DepHourofDay_16  DepHourofDay_17  DepHourofDay_18  DepHourofDay_19  \\\n",
       "0                   0.0              1.0              0.0              0.0   \n",
       "1                   0.0              0.0              0.0              0.0   \n",
       "2                   0.0              0.0              0.0              0.0   \n",
       "3                   0.0              0.0              0.0              0.0   \n",
       "4                   0.0              0.0              0.0              0.0   \n",
       "...                 ...              ...              ...              ...   \n",
       "205727              0.0              1.0              0.0              0.0   \n",
       "205728              0.0              0.0              0.0              1.0   \n",
       "205729              0.0              0.0              0.0              0.0   \n",
       "205730              0.0              0.0              0.0              0.0   \n",
       "205731              NaN              NaN              NaN              NaN   \n",
       "\n",
       "        DepHourofDay_20  DepHourofDay_21  DepHourofDay_22  DepHourofDay_23  \n",
       "0                   0.0              0.0              0.0              0.0  \n",
       "1                   0.0              0.0              0.0              0.0  \n",
       "2                   0.0              0.0              0.0              0.0  \n",
       "3                   0.0              1.0              0.0              0.0  \n",
       "4                   1.0              0.0              0.0              0.0  \n",
       "...                 ...              ...              ...              ...  \n",
       "205727              0.0              0.0              0.0              0.0  \n",
       "205728              0.0              0.0              0.0              0.0  \n",
       "205729              0.0              0.0              0.0              1.0  \n",
       "205730              0.0              0.0              0.0              0.0  \n",
       "205731              NaN              NaN              NaN              NaN  \n",
       "\n",
       "[200773 rows x 117 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.drop_duplicates(inplace=True)\n",
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define helper function to train deploy and test on AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import require libs\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.xgboost import XGBoost\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "# Set up SageMaker session and role and bucket \n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "\n",
    "# Specify your S3 bucket and data location\n",
    "## Get available bucket name\n",
    "s3_bucket = [bucket['Name'] for bucket in boto3.client('s3').list_buckets()['Buckets']][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `train_deploy_test` capture entires pipeline of train, validate, deploy and test (batch processing) and report model performance\n",
    "\n",
    "As it is required to run the same pipeline on 2 datasets and 2 training algorithms, it is easier to using this function to run for 4 scenarios with different parameters\n",
    "\n",
    "To train a model, 4 params are required\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_deploy_test(data, estimator_name, bucket, prefix):\n",
    "    \"\"\"\n",
    "        This function helps to run a pipeline on multiple datasets and estimator name\n",
    "        Params:\n",
    "            da,ta: a dataframe containing the first column as target variable and indicators as the rest\n",
    "            estimator_name: 'xgboost' or 'linear-learner' - Name of estimator suitable with AWS specs\n",
    "            bucket: a AWS bucket that can be used to upload data\n",
    "            prefix: a AWS folder to store uploaded data, due to using the same function for 4 different run, \n",
    "                    it is expected that prefix would be different for each to avoid data conflict\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Start train_deploy_test for {estimator_name} and store at s3://{bucket}/{prefix}\")\n",
    "\n",
    "    # Handle missing values if necessary\n",
    "    data = data.dropna()\n",
    "\n",
    "    # Split the dataset into features (X) and target (y)\n",
    "    X = data.drop('target', axis=1)  # Features\n",
    "    y = (data['target']).astype(int)  # Binary classification: 1 for delay, 0 for no delay\n",
    "\n",
    "    # Encode categorical features if needed (e.g., using one-hot encoding)\n",
    "    X = pd.get_dummies(X)\n",
    "\n",
    "    # Split the data into training, validation, and testing sets (70% - 15% - 15%)\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "    # Create RecordSets for the training, validation, and testing data\n",
    "    train_data = pd.concat([y_train, X_train], axis=1)\n",
    "    val_data = pd.concat([y_val, X_val], axis=1)\n",
    "    test_data = pd.concat([y_test, X_test], axis=1)\n",
    "\n",
    "    # Save train and validation data to support for the training process\n",
    "    train_data.to_csv('train_data.csv', header=False, index=False)\n",
    "    val_data.to_csv('val_data.csv', header=False, index=False)\n",
    "    \n",
    "    # Save testing data for supporting unknown testing. \n",
    "    # Due to the model prediction without a target column, \n",
    "    # the target column from test data is removed to work with the prediction phase later\n",
    "    test_data.drop(columns=[\"target\"]).to_csv('test_data.csv', header=False, index=False)\n",
    "\n",
    "    # Upload data to s3 ready for training and for later testing\n",
    "    s3_train_data = sagemaker_session.upload_data('train_data.csv', bucket=bucket, key_prefix=prefix)\n",
    "    s3_val_data = sagemaker_session.upload_data('val_data.csv', bucket=bucket, key_prefix=prefix)\n",
    "    s3_test_data = sagemaker_session.upload_data('test_data.csv', bucket=bucket, key_prefix=prefix)\n",
    "\n",
    "    # Create RecordSets for the training, validation, and not for testing data\n",
    "    train_recordset = sagemaker.inputs.TrainingInput(s3_data=s3_train_data, content_type='text/csv')\n",
    "    val_recordset = sagemaker.inputs.TrainingInput(s3_data=s3_val_data, content_type='text/csv')\n",
    "\n",
    "    # Train an classification model\n",
    "    estimator = sagemaker.estimator.Estimator(\n",
    "        role=role,\n",
    "        image_uri=sagemaker.image_uris.retrieve(estimator_name, boto3.Session().region_name, version='latest'),\n",
    "        instance_count=1,\n",
    "        instance_type='ml.m4.xlarge',\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        disable_profiler=True\n",
    "    )\n",
    "    # Identify params suitable for a provided estimator name\n",
    "    print(f\"Setting params for {estimator_name}\")\n",
    "    if estimator_name =='xgboost':\n",
    "        estimator.set_hyperparameters(\n",
    "            objective=\"binary:logistic\",\n",
    "            num_round=100,\n",
    "            max_depth=5,\n",
    "            eta=0.2,\n",
    "            alpha=0.1\n",
    "        )\n",
    "    elif estimator_name == 'linear-learner':\n",
    "        # Train the model on the RecordSet\n",
    "        estimator.set_hyperparameters(\n",
    "            predictor_type=\"binary_classifier\",\n",
    "            mini_batch_size=100,\n",
    "            epochs=10\n",
    "        )\n",
    "\n",
    "    # Start training the model with training set and validate using validation set\n",
    "    print(f'Start fitting : {estimator_name}')\n",
    "    estimator.fit({'train': train_recordset, 'validation': val_recordset})\n",
    "\n",
    "    # Deploy the trained model on another SageMaker instance\n",
    "    # The trained model is ready for both endpoint execution and batch processing\n",
    "    predictor = estimator.deploy(initial_instance_count=1, \n",
    "                                       instance_type='ml.m4.xlarge', \n",
    "                                       endpoint_name=estimator.latest_training_job.name,\n",
    "                                        model_name=estimator.latest_training_job.name\n",
    "                                      )\n",
    "    # Create a batch transform job for testing data\n",
    "    print('Create a batch transform job for testing data')\n",
    "    transformer = estimator.transformer(instance_count=1, \n",
    "                                      instance_type='ml.m4.xlarge', \n",
    "                                      accept='text/csv')\n",
    "    \n",
    "    # when testing, make sure test data won't have a target column to match with X structure\n",
    "    transformer.transform(data=s3_test_data, content_type='text/csv', split_type='Line')\n",
    "    transformer.wait()\n",
    "\n",
    "    # Download the results from S3\n",
    "    print('Download the results from S3')\n",
    "    s3_output_path = transformer.output_path\n",
    "    output_files = sagemaker.s3.S3Downloader.list(s3_output_path)\n",
    "\n",
    "    results = np.array([sagemaker.s3.S3Downloader.read_file(file).split() for file in output_files])\\\n",
    "    .astype(float)\n",
    "\n",
    "    # Calculate the number of records in the transformed data\n",
    "    num_records = len(results[0])\n",
    "    print(f'Obtain {num_records} from transformed data')\n",
    "\n",
    "    # Evaluate the model performance\n",
    "    print(\"Evaluate the model performance\")\n",
    "    y_pred = [int(result) for result in results[0]]\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    classification_report_str = classification_report(y_test, y_pred, target_names=['No Delay', 'Delay'])\n",
    "\n",
    "    print(f'Number of Records: {num_records}')\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion)\n",
    "    print('Classification Report:')\n",
    "    print(classification_report_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Build and evaluate simple models\n",
    "\n",
    "Write code to perform the follwoing steps:\n",
    "1. Split data into training, validation and testing sets (70% - 15% - 15%).\n",
    "2. Use linear learner estimator to build a classifcation model.\n",
    "3. Host the model on another instance\n",
    "4. Perform batch transform to evaluate the model on testing data\n",
    "5. Report the performance metrics that you see better test the model performance \n",
    "\n",
    "Note: You are required to perform the above steps on the two combined datasets separatey and to comments on the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start train_deploy_test for linear-learner and store at s3://c94466a2114432l5153128t1w680590409226-labbucket-1igwq1eolbjw9/flight-delay-prediction-linear-learner-dataset1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Same images used for training and inference. Defaulting to image scope: inference.\n",
      "WARNING:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting params for linear-learner\n",
      "Start fitting : linear-learner\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: linear-learner-2023-11-02-14-06-00-515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-02 14:06:00 Starting - Starting the training job....."
     ]
    }
   ],
   "source": [
    "# Define parameters to train a 'linear-learner'\n",
    "dataset = df_1\n",
    "estimator_name = 'linear-learner'\n",
    "s3_prefix = f'flight-delay-prediction-{estimator_name}-dataset1'\n",
    "train_deploy_test(dataset,estimator_name,s3_bucket,s3_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters to train a 'linear-learner'\n",
    "dataset = df_2\n",
    "estimator_name = 'linear-learner'\n",
    "s3_prefix = f'flight-delay-prediction-{estimator_name}-dataset2'\n",
    "train_deploy_test(dataset,estimator_name,s3_bucket,s3_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Build and evaluate ensembe models\n",
    "\n",
    "Write code to perform the follwoing steps:\n",
    "1. Split data into training, validation and testing sets (70% - 15% - 15%).\n",
    "2. Use xgboost estimator to build a classifcation model.\n",
    "3. Host the model on another instance\n",
    "4. Perform batch transform to evaluate the model on testing data\n",
    "5. Report the performance metrics that you see better test the model performance \n",
    "6. write down your observation on the difference between the performance of using the simple and ensemble models.\n",
    "Note: You are required to perform the above steps on the two combined datasets separatey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df_1\n",
    "estimator_name = 'xgboost' \n",
    "s3_prefix = f'flight-delay-prediction-{estimator_name}-dataset1'\n",
    "train_deploy_test(dataset,estimator_name,s3_bucket,s3_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df_2\n",
    "estimator_name = 'xgboost' \n",
    "s3_prefix = f'flight-delay-prediction-{estimator_name}-dataset2'\n",
    "train_deploy_test(dataset,estimator_name,s3_bucket,s3_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the final comments here and turn the cell type into markdown"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
